import numpy as np
import pandas as pd
import matplotlib.pyplot as plt
import seaborn as sns
from sklearn.model_selection import train_test_split, GridSearchCV, cross_val_score
from sklearn.linear_model import LogisticRegression
from sklearn.ensemble import RandomForestClassifier, GradientBoostingClassifier
from sklearn.preprocessing import StandardScaler, LabelEncoder
from sklearn.metrics import accuracy_score, classification_report, confusion_matrix, ConfusionMatrixDisplay
from sklearn.utils import resample
from sklearn.feature_selection import SelectKBest, f_classif
import warnings
warnings.filterwarnings('ignore')

# Set random seed for reproducibility
np.random.seed(42)

class FireTypeClassifier:
    def __init__(self):
        self.scaler = StandardScaler()
        self.models = {}
        self.best_model = None
        self.feature_selector = None
        
    def load_and_combine_data(self, file_paths):
        """Load and combine multiple CSV files"""
        dataframes = []
        for file_path in file_paths:
            df = pd.read_csv(file_path)
            dataframes.append(df)
        return pd.concat(dataframes, ignore_index=True)
    
    def advanced_eda(self, df):
        """Perform comprehensive exploratory data analysis"""
        print("üî• MODIS Fire Classification - Advanced EDA üî•")
        print("=" * 60)
        
        # Basic info
        print(f"Dataset Shape: {df.shape}")
        print(f"Memory Usage: {df.memory_usage(deep=True).sum() / 1024**2:.2f} MB")
        
        # Target distribution
        plt.figure(figsize=(15, 10))
        
        # 1. Enhanced target distribution
        plt.subplot(2, 3, 1)
        target_counts = df['type'].value_counts()
        colors = ['#FF6B6B', '#4ECDC4', '#45B7D1', '#96CEB4']
        bars = plt.bar(target_counts.index, target_counts.values, color=colors[:len(target_counts)])
        plt.title('Fire Type Distribution', fontsize=14, fontweight='bold')
        plt.xlabel('Fire Type')
        plt.ylabel('Count')
        
        # Add value labels on bars
        for bar in bars:
            height = bar.get_height()
            plt.text(bar.get_x() + bar.get_width()/2., height + height*0.01,
                    f'{int(height):,}', ha='center', va='bottom')
        
        # 2. Confidence by fire type
        plt.subplot(2, 3, 2)
        sns.boxplot(data=df, x='type', y='confidence', palette='viridis')
        plt.title('Confidence Distribution by Fire Type', fontweight='bold')
        plt.xticks(rotation=45)
        
        # 3. Brightness vs FRP colored by type
        plt.subplot(2, 3, 3)
        for fire_type in df['type'].unique():
            subset = df[df['type'] == fire_type]
            plt.scatter(subset['brightness'], subset['frp'], 
                       label=f'Type {fire_type}', alpha=0.6, s=20)
        plt.xlabel('Brightness (K)')
        plt.ylabel('Fire Radiative Power (MW)')
        plt.title('Brightness vs FRP by Fire Type', fontweight='bold')
        plt.legend()
        
        # 4. Temporal analysis
        plt.subplot(2, 3, 4)
        df['acq_datetime'] = pd.to_datetime(df['acq_date'])
        df['month'] = df['acq_datetime'].dt.month
        monthly_fires = df.groupby(['month', 'type']).size().unstack(fill_value=0)
        monthly_fires.plot(kind='bar', stacked=True, ax=plt.gca())
        plt.title('Monthly Fire Distribution by Type', fontweight='bold')
        plt.xlabel('Month')
        plt.ylabel('Number of Fires')
        plt.xticks(rotation=45)
        
        # 5. Satellite distribution
        plt.subplot(2, 3, 5)
        satellite_counts = df['satellite'].value_counts()
        plt.pie(satellite_counts.values, labels=satellite_counts.index, autopct='%1.1f%%')
        plt.title('Data Distribution by Satellite', fontweight='bold')
        
        # 6. Correlation heatmap
        plt.subplot(2, 3, 6)
        numeric_cols = ['latitude', 'longitude', 'brightness', 'scan', 'track', 
                       'confidence', 'bright_t31', 'frp']
        correlation_matrix = df[numeric_cols].corr()
        sns.heatmap(correlation_matrix, annot=True, cmap='coolwarm', center=0, 
                   square=True, fmt='.2f')
        plt.title('Feature Correlation Matrix', fontweight='bold')
        
        plt.tight_layout()
        plt.show()
        
        return df
    
    def feature_engineering(self, df):
        """Create new features from existing ones"""
        print("\nüîß Feature Engineering...")
        
        # Time-based features
        df['acq_datetime'] = pd.to_datetime(df['acq_date'])
        df['year'] = df['acq_datetime'].dt.year
        df['month'] = df['acq_datetime'].dt.month
        df['day_of_year'] = df['acq_datetime'].dt.dayofyear
        df['season'] = df['month'].map({12: 'Winter', 1: 'Winter', 2: 'Winter',
                                       3: 'Spring', 4: 'Spring', 5: 'Spring',
                                       6: 'Summer', 7: 'Summer', 8: 'Summer',
                                       9: 'Autumn', 10: 'Autumn', 11: 'Autumn'})
        
        # Spatial features
        df['lat_lon_interaction'] = df['latitude'] * df['longitude']
        
        # Temperature difference
        df['temp_diff'] = df['brightness'] - df['bright_t31']
        
        # FRP intensity categories
        df['frp_category'] = pd.cut(df['frp'], bins=[0, 10, 50, 200, np.inf], 
                                   labels=['Low', 'Medium', 'High', 'Very High'])
        
        # Confidence categories
        df['confidence_category'] = pd.cut(df['confidence'], bins=[0, 30, 70, 100], 
                                          labels=['Low', 'Medium', 'High'])
        
        # Encode categorical variables
        le_satellite = LabelEncoder()
        le_daynight = LabelEncoder()
        le_season = LabelEncoder()
        le_frp_cat = LabelEncoder()
        le_conf_cat = LabelEncoder()
        
        df['satellite_encoded'] = le_satellite.fit_transform(df['satellite'])
        df['daynight_encoded'] = le_daynight.fit_transform(df['daynight'])
        df['season_encoded'] = le_season.fit_transform(df['season'])
        df['frp_category_encoded'] = le_frp_cat.fit_transform(df['frp_category'])
        df['confidence_category_encoded'] = le_conf_cat.fit_transform(df['confidence_category'])
        
        print(f"‚úÖ Created {len(df.columns) - 15} new features")
        return df
    
    def prepare_features(self, df):
        """Select and prepare features for modeling"""
        feature_columns = [
            'latitude', 'longitude', 'brightness', 'scan', 'track', 'confidence',
            'bright_t31', 'frp', 'year', 'month', 'day_of_year', 'lat_lon_interaction',
            'temp_diff', 'satellite_encoded', 'daynight_encoded', 'season_encoded',
            'frp_category_encoded', 'confidence_category_encoded'
        ]
        
        X = df[feature_columns]
        y = df['type']
        
        return X, y
    
    def handle_class_imbalance(self, X, y):
        """Handle class imbalance using SMOTE-like oversampling"""
        print("\n‚öñÔ∏è Handling Class Imbalance...")
        
        # Combine X and y for resampling
        df_combined = pd.concat([X, y], axis=1)
        
        # Separate classes
        class_0 = df_combined[df_combined['type'] == 0]
        class_2 = df_combined[df_combined['type'] == 2]
        class_3 = df_combined[df_combined['type'] == 3]
        
        # Determine target size (use the size of the majority class)
        max_size = max(len(class_0), len(class_2), len(class_3))
        target_size = min(max_size, 50000)  # Cap at 50k to avoid memory issues
        
        # Oversample minority classes
        class_0_upsampled = resample(class_0, replace=True, n_samples=target_size, random_state=42)
        class_2_upsampled = resample(class_2, replace=True, n_samples=target_size, random_state=42)
        class_3_upsampled = resample(class_3, replace=True, n_samples=target_size, random_state=42)
        
        # Combine upsampled classes
        df_balanced = pd.concat([class_0_upsampled, class_2_upsampled, class_3_upsampled])
        
        # Shuffle the dataset
        df_balanced = df_balanced.sample(frac=1, random_state=42).reset_index(drop=True)
        
        X_balanced = df_balanced.drop('type', axis=1)
        y_balanced = df_balanced['type']
        
        print(f"‚úÖ Balanced dataset shape: {X_balanced.shape}")
        print("Class distribution after balancing:")
        print(y_balanced.value_counts().sort_index())
        
        return X_balanced, y_balanced
    
    def feature_selection(self, X_train, y_train, k=15):
        """Select top k features based on statistical tests"""
        print(f"\nüéØ Selecting top {k} features...")
        
        self.feature_selector = SelectKBest(score_func=f_classif, k=k)
        X_train_selected = self.feature_selector.fit_transform(X_train, y_train)
        
        # Get selected feature names
        selected_features = X_train.columns[self.feature_selector.get_support()].tolist()
        print(f"‚úÖ Selected features: {selected_features}")
        
        return X_train_selected, selected_features
    
    def train_models(self, X_train, y_train, X_test, y_test):
        """Train multiple models and compare performance"""
        print("\nüöÄ Training Multiple Models...")
        
        # Define models
        models = {
            'Logistic Regression': LogisticRegression(random_state=42, max_iter=1000),
            'Random Forest': RandomForestClassifier(random_state=42, n_estimators=100),
            'Gradient Boosting': GradientBoostingClassifier(random_state=42, n_estimators=100)
        }
        
        results = {}
        
        for name, model in models.items():
            print(f"\nTraining {name}...")
            
            # Train model
            model.fit(X_train, y_train)
            
            # Make predictions
            y_pred = model.predict(X_test)
            
            # Calculate accuracy
            accuracy = accuracy_score(y_test, y_pred)
            
            # Cross-validation score
            cv_scores = cross_val_score(model, X_train, y_train, cv=5, scoring='accuracy')
            
            results[name] = {
                'model': model,
                'accuracy': accuracy,
                'cv_mean': cv_scores.mean(),
                'cv_std': cv_scores.std(),
                'predictions': y_pred
            }
            
            print(f"‚úÖ {name} - Accuracy: {accuracy:.4f}, CV Score: {cv_scores.mean():.4f} (¬±{cv_scores.std():.4f})")
        
        # Find best model
        best_model_name = max(results.keys(), key=lambda x: results[x]['cv_mean'])
        self.best_model = results[best_model_name]['model']
        self.models = results
        
        print(f"\nüèÜ Best Model: {best_model_name}")
        
        return results
    
    def hyperparameter_tuning(self, X_train, y_train):
        """Perform hyperparameter tuning for the best model"""
        print("\nüîß Hyperparameter Tuning...")
        
        if isinstance(self.best_model, RandomForestClassifier):
            param_grid = {
                'n_estimators': [50, 100, 200],
                'max_depth': [10, 20, None],
                'min_samples_split': [2, 5, 10]
            }
        elif isinstance(self.best_model, GradientBoostingClassifier):
            param_grid = {
                'n_estimators': [50, 100, 200],
                'learning_rate': [0.01, 0.1, 0.2],
                'max_depth': [3, 5, 7]
            }
        else:
            param_grid = {
                'C': [0.1, 1, 10],
                'solver': ['liblinear', 'lbfgs']
            }
        
        grid_search = GridSearchCV(
            self.best_model, param_grid, cv=3, scoring='accuracy',
            n_jobs=-1, verbose=1
        )
        
        grid_search.fit(X_train, y_train)
        
        print(f"‚úÖ Best parameters: {grid_search.best_params_}")
        print(f"‚úÖ Best CV score: {grid_search.best_score_:.4f}")
        
        self.best_model = grid_search.best_estimator_
        
        return grid_search.best_estimator_
    
    def evaluate_model(self, X_test, y_test, selected_features=None):
        """Comprehensive model evaluation"""
        print("\nüìä Model Evaluation...")
        
        y_pred = self.best_model.predict(X_test)
        
        # Accuracy
        accuracy = accuracy_score(y_test, y_pred)
        print(f"‚úÖ Final Test Accuracy: {accuracy:.4f}")
        
        # Classification report
        print("\nüìã Classification Report:")
        print(classification_report(y_test, y_pred))
        
        # Confusion Matrix
        plt.figure(figsize=(12, 5))
        
        plt.subplot(1, 2, 1)
        cm = confusion_matrix(y_test, y_pred)
        sns.heatmap(cm, annot=True, fmt='d', cmap='Blues')
        plt.title('Confusion Matrix')
        plt.ylabel('True Label')
        plt.xlabel('Predicted Label')
        
        # Feature importance (if available)
        if hasattr(self.best_model, 'feature_importances_') and selected_features:
            plt.subplot(1, 2, 2)
            importance_df = pd.DataFrame({
                'feature': selected_features,
                'importance': self.best_model.feature_importances_
            }).sort_values('importance', ascending=True)
            
            plt.barh(importance_df['feature'], importance_df['importance'])
            plt.title('Feature Importance')
            plt.xlabel('Importance')
        
        plt.tight_layout()
        plt.show()
        
        return accuracy, y_pred
    
    def run_complete_pipeline(self, file_paths):
        """Run the complete machine learning pipeline"""
        print("üî• MODIS Fire Type Classification Pipeline üî•")
        print("=" * 60)
        
        # 1. Load data
        print("üìÅ Loading data...")
        df = self.load_and_combine_data(file_paths)
        
        # 2. Advanced EDA
        df = self.advanced_eda(df)
        
        # 3. Feature engineering
        df = self.feature_engineering(df)
        
        # 4. Prepare features
        X, y = self.prepare_features(df)
        
        # 5. Handle class imbalance
        X_balanced, y_balanced = self.handle_class_imbalance(X, y)
        
        # 6. Split data
        X_train, X_test, y_train, y_test = train_test_split(
            X_balanced, y_balanced, test_size=0.2, random_state=42, stratify=y_balanced
        )
        
        # 7. Scale features
        X_train_scaled = self.scaler.fit_transform(X_train)
        X_test_scaled = self.scaler.transform(X_test)
        
        # Convert back to DataFrame for feature selection
        X_train_scaled = pd.DataFrame(X_train_scaled, columns=X_train.columns)
        X_test_scaled = pd.DataFrame(X_test_scaled, columns=X_test.columns)
        
        # 8. Feature selection
        X_train_selected, selected_features = self.feature_selection(X_train_scaled, y_train)
        X_test_selected = self.feature_selector.transform(X_test_scaled)
        
        # 9. Train models
        results = self.train_models(X_train_selected, y_train, X_test_selected, y_test)
        
        # 10. Hyperparameter tuning
        tuned_model = self.hyperparameter_tuning(X_train_selected, y_train)
        
        # 11. Final evaluation
        accuracy, predictions = self.evaluate_model(X_test_selected, y_test, selected_features)
        
        return {
            'accuracy': accuracy,
            'model': self.best_model,
            'selected_features': selected_features,
            'scaler': self.scaler,
            'feature_selector': self.feature_selector
        }

# Usage
if __name__ == "__main__":
    # Initialize classifier
    classifier = FireTypeClassifier()
    
    # File paths
    file_paths = ['modis_2021_India.csv', 'modis_2022_India.csv', 'modis_2023_India.csv']
    
    # Run complete pipeline
    results = classifier.run_complete_pipeline(file_paths)
    
    print(f"\nüéâ Pipeline Complete! Final Accuracy: {results['accuracy']:.4f}")
